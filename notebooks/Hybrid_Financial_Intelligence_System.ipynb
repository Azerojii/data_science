{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Hybrid Financial Intelligence System\n", "\n", "__Use case:__ Predict whether high-volatility stocks (SMCI, CRSP, PLTR) will gain more than 3.5% over the next 5 trading days.\n", "\n", "__Dataset:__ Daily OHLCV price data from Yahoo Finance, plus a macro factor (10-Year Treasury Yield from FRED). The target is a binary label: 1 if the 5-day forward return exceeds 3.5%, 0 otherwise."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Importing the Dataset"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import os"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["data_dir = os.path.join('..', 'data')\n", "os.listdir(data_dir)"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["prices_path = os.path.join(data_dir, 'prices_daily.csv')\n", "raw_df = pd.read_csv(prices_path, parse_dates=['date'])\n", "raw_df"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["raw_df.shape"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["raw_df.info()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["We have daily OHLCV data for 3 tickers. Let's check what tickers are in the dataset and the date range."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["print('Tickers:', raw_df['ticker'].unique())\n", "print('Date range:', raw_df['date'].min(), 'to', raw_df['date'].max())\n", "print('Rows per ticker:')\n", "raw_df['ticker'].value_counts()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["raw_df.describe()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Let's also check for missing values."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["raw_df.isna().sum()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["No missing values in the price data. Now let's load the macro factor (10-Year Treasury Yield)."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["macro_path = os.path.join(data_dir, 'macro_10y_yield.csv')\n", "macro_df = pd.read_csv(macro_path, parse_dates=['date'])\n", "macro_df"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["macro_df.info()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["We need to merge the macro data with the price data. Since bond yields are only reported on business days, we'll forward-fill to cover weekends and holidays."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Expand macro to full calendar and forward-fill gaps\n", "full_range = pd.date_range(macro_df['date'].min(), raw_df['date'].max(), freq='D')\n", "macro_full = macro_df.set_index('date').reindex(full_range).ffill().rename_axis('date').reset_index()\n", "\n", "# Merge with prices\n", "merged = raw_df.merge(macro_full, on='date', how='left')\n", "merged"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["merged.isna().sum()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Good, the merge went smoothly. Let's check a few rows to make sure the yield values look reasonable."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["merged[['date', 'ticker', 'adj_close', 'ten_year_yield']].sample(5, random_state=42)"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Exploratory Data Analysis and Visualization"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import plotly.express as px\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Normalized Price Paths\n", "\n", "To compare tickers with very different price levels, we normalize each to start at 100."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["price_pivot = merged.pivot_table(index='date', columns='ticker', values='adj_close')\n", "normalized = price_pivot / price_pivot.iloc[0] * 100\n", "\n", "fig = px.line(normalized, title='Normalized Price Paths (base = 100)')\n", "fig.update_layout(yaxis_title='Indexed Price', xaxis_title='Date')\n", "fig.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- SMCI shows the most dramatic moves, with huge rallies and sharp drawdowns\n", "- PLTR has a more stable uptrend since late 2022\n", "- CRSP tends to move independently from the other two\n", "- All three are clearly high-volatility names $\\rightarrow$ a higher success threshold (3.5%) makes sense here"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Histogram: Daily Returns by Ticker"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Compute daily returns\n", "merged = merged.sort_values(['ticker', 'date'])\n", "merged['daily_return'] = merged.groupby('ticker')['adj_close'].pct_change()\n", "\n", "fig = px.histogram(merged.dropna(subset=['daily_return']), x='daily_return', color='ticker',\n", "                   nbins=100, opacity=0.6, barmode='overlay',\n", "                   title='Distribution of Daily Returns by Ticker')\n", "fig.update_layout(xaxis_title='Daily Return', yaxis_title='Count')\n", "fig.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- SMCI has noticeably fatter tails $\\rightarrow$ more extreme daily moves (both up and down)\n", "- All three tickers show roughly symmetric distributions centered near 0\n", "- The spread confirms these are genuinely high-volatility stocks"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Scatter Plot: Volume vs Absolute Daily Return"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["merged['abs_return'] = merged['daily_return'].abs()\n", "\n", "# Sample to keep the plot readable\n", "sample = merged.dropna(subset=['abs_return']).sample(2000, random_state=42)\n", "\n", "fig = px.scatter(sample, x='volume', y='abs_return', color='ticker',\n", "                opacity=0.4, title='Volume vs Absolute Daily Return')\n", "fig.update_layout(xaxis_title='Volume', yaxis_title='|Daily Return|')\n", "fig.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- Higher volume days tend to have larger absolute returns, which makes sense\n", "- SMCI shows some extreme outliers on both axes\n", "- This relationship suggests volume-based features could be useful for the model"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Scatter Plot: MinTemp vs MaxTemp Equivalent (Low vs High Price)"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["sample2 = merged.sample(2000, random_state=42)\n", "fig = px.scatter(sample2, x='low', y='high', color='ticker',\n", "                opacity=0.4, title='Daily Low vs High Price by Ticker')\n", "fig.update_layout(xaxis_title='Low', yaxis_title='High')\n", "fig.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- Strong linear correlation between daily low and high (as expected)\n", "- SMCI occupies a much wider range, reflecting bigger intraday swings\n", "- The spread between low and high within a day is essentially what ATR captures"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Treasury Yield Over Time"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig = px.line(macro_full, x='date', y='ten_year_yield',\n", "             title='10-Year Treasury Yield Over Time')\n", "fig.update_layout(yaxis_title='Yield (%)', xaxis_title='Date')\n", "fig.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- Sharp rise from 2022 onward, which coincides with the Fed rate-hiking cycle\n", "- The yield environment shifted significantly during our data period $\\rightarrow$ including it as a macro feature is justified"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Summary Statistics per Ticker"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["summary = merged.groupby('ticker').agg(\n", "    obs=('adj_close', 'count'),\n", "    close_mean=('adj_close', 'mean'),\n", "    close_std=('adj_close', 'std'),\n", "    close_min=('adj_close', 'min'),\n", "    close_max=('adj_close', 'max'),\n", "    volume_mean=('volume', 'mean'),\n", "    daily_vol=('daily_return', 'std'),\n", "    mean_return=('daily_return', 'mean')\n", ").round(4)\n", "summary"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- SMCI has the highest daily volatility and the widest price range\n", "- Daily returns average close to zero for all tickers, but the standard deviations differ a lot\n", "- These numbers confirm the high-volatility regime: typical 5-day moves can easily exceed 3.5%"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Feature Engineering\n", "\n", "We'll compute standard technical indicators for each ticker, then build rolling-window features."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import ta"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Adding Technical Indicators\n", "\n", "We compute per ticker: RSI(14), MACD(12,26,9), Bollinger Bands(20), moving averages (50, 200), volume z-score, and ATR(14)."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["featured_parts = []\n", "\n", "for ticker, g in merged.groupby('ticker', group_keys=False):\n", "    g = g.copy().sort_values('date')\n", "    close = g['adj_close'].astype(float)\n", "    high = g['high'].astype(float)\n", "    low = g['low'].astype(float)\n", "    volume = g['volume'].astype(float)\n", "\n", "    # RSI\n", "    g['rsi_14'] = ta.momentum.RSIIndicator(close).rsi()\n", "\n", "    # MACD\n", "    macd = ta.trend.MACD(close)\n", "    g['macd'] = macd.macd()\n", "    g['macd_signal'] = macd.macd_signal()\n", "    g['macd_hist'] = macd.macd_diff()\n", "\n", "    # Bollinger Bands\n", "    bb = ta.volatility.BollingerBands(close)\n", "    g['bb_high'] = bb.bollinger_hband()\n", "    g['bb_low'] = bb.bollinger_lband()\n", "    g['bb_width'] = (bb.bollinger_hband() - bb.bollinger_lband()) / close\n", "\n", "    # Moving averages\n", "    g['ma_50'] = close.rolling(50).mean()\n", "    g['ma_200'] = close.rolling(200).mean()\n", "\n", "    # Volume z-score\n", "    g['volume_z'] = (volume - volume.rolling(50).mean()) / (volume.rolling(50).std() + 1e-9)\n", "\n", "    # ATR (Average True Range)\n", "    atr_ind = ta.volatility.AverageTrueRange(high=high, low=low, close=close, window=14)\n", "    g['atr_14'] = atr_ind.average_true_range()\n", "    g['atr_pct'] = (g['atr_14'] / close) * 100\n", "\n", "    featured_parts.append(g)\n", "\n", "featured = pd.concat(featured_parts, ignore_index=True)\n", "print(f'Shape after adding indicators: {featured.shape}')\n", "featured.head()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Let's check how many NaN values we introduced (indicators need a warm-up period)."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["featured[['rsi_14', 'macd', 'bb_width', 'ma_50', 'ma_200', 'atr_14']].isna().sum()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["MA(200) has the most missing values because it needs 200 days of data to start computing. These NaN rows will be handled when we build the rolling-window dataset."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## ATR Distribution by Ticker"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, ax = plt.subplots(figsize=(10, 5))\n", "sns.boxplot(data=featured.dropna(subset=['atr_14']), x='ticker', y='atr_14', ax=ax)\n", "ax.set_title('ATR(14) Distribution by Ticker')\n", "ax.set_ylabel('ATR (14-day)')\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- SMCI has a much higher and more spread-out ATR, confirming its extreme volatility\n", "- ATR-based features will help the model distinguish between normal and abnormal price action\n", "- We also use ATR as a percentage of price (`atr_pct`) so it's comparable across tickers"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Creating the Target Variable\n", "\n", "For each row, we compute the 5-day forward return and label it 1 if it exceeds 3.5%."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["HORIZON = 5\n", "THRESHOLD = 0.035  # 3.5%\n", "\n", "target_parts = []\n", "for ticker, g in featured.groupby('ticker', group_keys=False):\n", "    g = g.copy().sort_values('date')\n", "    close = g['adj_close'].astype(float)\n", "    future_price = close.shift(-HORIZON)\n", "    g['future_return'] = future_price / close - 1.0\n", "    g['target'] = (g['future_return'] > THRESHOLD).astype(int)\n", "    target_parts.append(g)\n", "\n", "featured = pd.concat(target_parts, ignore_index=True)\n", "featured[['date', 'ticker', 'adj_close', 'future_return', 'target']].tail(10)"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Let's see the class balance."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["target_counts = featured['target'].value_counts()\n", "print(target_counts)\n", "print(f'\\nPositive class ratio: {target_counts.get(1, 0) / target_counts.sum():.4f}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Histogram: 5-Day Forward Returns"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig = px.histogram(featured.dropna(subset=['future_return']), x='future_return',\n", "                   nbins=80, title='Distribution of 5-Day Forward Returns')\n", "fig.add_vline(x=THRESHOLD, line_dash='dash', line_color='red',\n", "              annotation_text=f'Threshold = {THRESHOLD:.1%}')\n", "fig.update_layout(xaxis_title='5-Day Forward Return', yaxis_title='Count')\n", "fig.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- The distribution has fat tails on both sides, typical of high-volatility stocks\n", "- A decent portion of observations exceed the 3.5% threshold\n", "- There are also extreme negative returns $\\rightarrow$ a long/cash strategy (no shorting) is safer"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Building the Rolling Window Dataset\n", "\n", "Instead of using raw indicator values (which change scale over time), we compute rolling statistics over a 14-day window: mean, standard deviation, and last value for each indicator."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["WINDOW = 14\n", "\n", "feature_cols = ['adj_close', 'rsi_14', 'macd', 'macd_signal', 'macd_hist',\n", "                'bb_width', 'ma_50', 'ma_200', 'volume_z',\n", "                'atr_14', 'atr_pct', 'ten_year_yield']\n", "\n", "rows = []\n", "for ticker, g in featured.groupby('ticker'):\n", "    g = g.sort_values('date').reset_index(drop=True)\n", "    for idx in range(WINDOW, len(g) - HORIZON):\n", "        window = g.iloc[idx - WINDOW : idx]\n", "        current = g.iloc[idx]\n", "\n", "        if pd.isna(current['target']) or pd.isna(current['future_return']):\n", "            continue\n", "\n", "        stats = {}\n", "        for col in feature_cols:\n", "            if col not in window.columns:\n", "                continue\n", "            s = window[col].astype(float)\n", "            stats[f'{col}_mean'] = s.mean(skipna=True)\n", "            stats[f'{col}_std'] = s.std(skipna=True)\n", "            last_valid = s.dropna()\n", "            stats[f'{col}_last'] = last_valid.iloc[-1] if len(last_valid) > 0 else np.nan\n", "\n", "        row = {\n", "            'ticker': current['ticker'],\n", "            'date': current['date'],\n", "            'target': int(current['target']),\n", "            'future_return': current['future_return'],\n", "            **stats\n", "        }\n", "        rows.append(row)\n", "\n", "dataset = pd.DataFrame(rows)\n", "\n", "# Fill remaining NaN in features with 0\n", "feat_cols_to_fill = [c for c in dataset.columns if c not in ['ticker', 'date', 'target', 'future_return']]\n", "dataset[feat_cols_to_fill] = dataset[feat_cols_to_fill].fillna(0)\n", "dataset = dataset.reset_index(drop=True)\n", "\n", "print(f'Dataset shape: {dataset.shape}')\n", "print(f'Features: {len(feat_cols_to_fill)}')\n", "dataset.head()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["print(f'Target distribution:')\n", "print(dataset['target'].value_counts())\n", "print(f'\\nPositive class ratio: {dataset[\"target\"].mean():.4f}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Target Class Balance"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, ax = plt.subplots(figsize=(6, 4))\n", "sns.countplot(data=dataset, x='target', ax=ax)\n", "ax.set_title('Target Class Balance')\n", "ax.set_xlabel('Target (1 = 5-day return > 3.5%)')\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- The classes are not perfectly balanced but it's not extreme either\n", "- We'll use `scale_pos_weight` in XGBoost to compensate for the imbalance"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Feature Correlations with Target"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["corr_with_target = dataset[feat_cols_to_fill + ['target']].corr()['target'].drop('target')\n", "top_corr = corr_with_target.abs().sort_values(ascending=False).head(18)\n", "top_features = corr_with_target[top_corr.index].sort_values()\n", "\n", "fig, ax = plt.subplots(figsize=(10, 6))\n", "colors = ['green' if v > 0 else 'red' for v in top_features.values]\n", "top_features.plot(kind='barh', color=colors, ax=ax)\n", "ax.set_title('Top 18 Feature Correlations with Target')\n", "ax.set_xlabel('Correlation')\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- Some ATR and volatility-related features show decent correlation with the target\n", "- RSI features and momentum indicators also appear useful\n", "- No single feature is extremely predictive on its own $\\rightarrow$ we need a model that can combine them"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Dividing Data into Training and Test Sets\n", "\n", "Since this is time-series data, we split chronologically: everything before 2023 is training, everything from 2023 onward is the test set. This prevents data leakage."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["CUTOFF = '2023-01-01'\n", "\n", "dataset = dataset.sort_values('date').reset_index(drop=True)\n", "\n", "train_df = dataset[dataset['date'] < CUTOFF].copy()\n", "test_df = dataset[dataset['date'] >= CUTOFF].copy()\n", "\n", "print(f'Training set: {len(train_df)} rows')\n", "print(f'Test set:     {len(test_df)} rows')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Let's see the date ranges\n", "print(f'Train: {train_df[\"date\"].min().date()} to {train_df[\"date\"].max().date()}')\n", "print(f'Test:  {test_df[\"date\"].min().date()} to {test_df[\"date\"].max().date()}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Identifying Input and Target Columns"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# We exclude metadata columns from features\n", "exclude = ['ticker', 'date', 'target', 'future_return']\n", "input_cols = [c for c in dataset.columns if c not in exclude]\n", "target_col = 'target'\n", "\n", "print(f'Number of input features: {len(input_cols)}')\n", "print(f'Target column: {target_col}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["train_inputs = train_df[input_cols].copy()\n", "train_targets = train_df[target_col].copy()\n", "\n", "test_inputs = test_df[input_cols].copy()\n", "test_targets = test_df[target_col].copy()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["train_inputs.describe()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["The features have very different scales (some are in hundreds, some near zero). We need to scale them."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Scaling Numeric Features\n", "\n", "We use MinMaxScaler to bring everything into the [0, 1] range. We fit the scaler on the training set only to avoid leaking test information."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from sklearn.preprocessing import MinMaxScaler"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["scaler = MinMaxScaler()\n", "scaler.fit(train_inputs)\n", "\n", "train_inputs_scaled = pd.DataFrame(scaler.transform(train_inputs), columns=input_cols, index=train_inputs.index)\n", "test_inputs_scaled = pd.DataFrame(scaler.transform(test_inputs), columns=input_cols, index=test_inputs.index)"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Verify the scaling worked\n", "train_inputs_scaled.describe()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["The minimum is now 0 (or close) and the maximum is 1 for all columns in the training set. The test set might slightly exceed [0, 1] if test values go outside the training range, which is expected."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Training an XGBoost Model"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from xgboost import XGBClassifier\n", "from sklearn.model_selection import TimeSeriesSplit\n", "from sklearn.metrics import classification_report, precision_score"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["We train with 5-fold time-series cross-validation. This respects the temporal order: each fold uses only past data for training."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Handle class imbalance\n", "n_pos = train_targets.sum()\n", "n_neg = len(train_targets) - n_pos\n", "spw = n_neg / n_pos\n", "print(f'Negative samples: {n_neg}, Positive samples: {n_pos}')\n", "print(f'scale_pos_weight: {spw:.2f}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["SEED = 42\n", "\n", "tscv = TimeSeriesSplit(n_splits=5)\n", "best_precision = -1\n", "best_model = None\n", "\n", "X_train = train_inputs_scaled.values\n", "y_train = train_targets.values\n", "\n", "for fold, (tr_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n", "    X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n", "    y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n", "\n", "    model = XGBClassifier(\n", "        n_estimators=300, max_depth=4, learning_rate=0.05,\n", "        subsample=0.9, colsample_bytree=0.9,\n", "        scale_pos_weight=spw, objective='binary:logistic',\n", "        eval_metric='logloss', random_state=SEED, n_jobs=-1\n", "    )\n", "    model.fit(X_tr, y_tr)\n", "\n", "    y_pred = model.predict(X_val)\n", "    prec = precision_score(y_val, y_pred, zero_division=0)\n", "    print(f'Fold {fold}: precision = {prec:.4f}')\n", "\n", "    if prec > best_precision:\n", "        best_precision = prec\n", "        best_model = model\n", "\n", "print(f'\\nBest CV precision: {best_precision:.4f}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Examining Feature Importances\n", "\n", "Let's see which features the model relies on most."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["importances = best_model.feature_importances_\n", "feat_imp = pd.DataFrame({'feature': input_cols, 'importance': importances})\n", "feat_imp = feat_imp.sort_values('importance', ascending=False)\n", "feat_imp.head(15)"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, ax = plt.subplots(figsize=(10, 6))\n", "top15 = feat_imp.head(15).sort_values('importance')\n", "ax.barh(top15['feature'], top15['importance'], color='steelblue')\n", "ax.set_title('Top 15 Feature Importances (XGBoost)')\n", "ax.set_xlabel('Importance')\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- ATR and volatility-related features rank highly, which aligns with our EDA findings\n", "- The model uses a mix of momentum (RSI, MACD) and volatility features\n", "- The macro factor (treasury yield) also contributes"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Making Predictions and Evaluating the Model"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Evaluating on Training Set\n", "\n", "First, let's retrain the best model on the full training set and check performance."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Retrain on full training data\n", "final_model = XGBClassifier(\n", "    n_estimators=300, max_depth=4, learning_rate=0.05,\n", "    subsample=0.9, colsample_bytree=0.9,\n", "    scale_pos_weight=spw, objective='binary:logistic',\n", "    eval_metric='logloss', random_state=SEED, n_jobs=-1\n", ")\n", "final_model.fit(X_train, y_train)\n", "\n", "train_pred = final_model.predict(X_train)\n", "print(classification_report(y_train, train_pred, zero_division=0))"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Get probabilities for threshold tuning later\n", "train_proba = final_model.predict_proba(X_train)[:, 1]"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Evaluating on Test Set"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["X_test = test_inputs_scaled.values\n", "y_test = test_targets.values\n", "\n", "test_pred = final_model.predict(X_test)\n", "print(classification_report(y_test, test_pred, zero_division=0))"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["test_proba = final_model.predict_proba(X_test)[:, 1]"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## ROC Curve"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from sklearn.metrics import roc_auc_score, roc_curve"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# ROC-AUC\n", "try:\n", "    auc_train = roc_auc_score(y_train, train_proba)\n", "    auc_test = roc_auc_score(y_test, test_proba)\n", "    print(f'ROC-AUC (train): {auc_train:.4f}')\n", "    print(f'ROC-AUC (test):  {auc_test:.4f}')\n", "except ValueError as e:\n", "    print(f'Could not compute AUC: {e}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Plot ROC curve for the test set\n", "fpr, tpr, _ = roc_curve(y_test, test_proba)\n", "\n", "fig, ax = plt.subplots(figsize=(8, 6))\n", "ax.plot(fpr, tpr, label=f'XGBoost (AUC = {auc_test:.3f})', color='steelblue')\n", "ax.plot([0, 1], [0, 1], 'k--', label='Random baseline')\n", "ax.set_xlabel('False Positive Rate')\n", "ax.set_ylabel('True Positive Rate')\n", "ax.set_title('ROC Curve (Test Set)')\n", "ax.legend()\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Confusion Matrix"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from sklearn.metrics import confusion_matrix\n", "\n", "cm = confusion_matrix(y_test, test_pred)\n", "fig, ax = plt.subplots(figsize=(6, 5))\n", "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n", "            xticklabels=['No (0)', 'Yes (1)'], yticklabels=['No (0)', 'Yes (1)'])\n", "ax.set_xlabel('Predicted')\n", "ax.set_ylabel('Actual')\n", "ax.set_title('Confusion Matrix (Test Set)')\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Threshold Tuning\n", "\n", "The default threshold of 0.5 might not be optimal. In a trading context, precision matters a lot: we'd rather miss some opportunities (lower recall) than make bad trades (low precision). Let's sweep different thresholds."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from sklearn.metrics import recall_score, f1_score\n", "\n", "thresholds = np.arange(0.30, 0.85, 0.05)\n", "results = []\n", "\n", "for t in thresholds:\n", "    preds = (test_proba >= t).astype(int)\n", "    n_signals = preds.sum()\n", "    coverage = n_signals / len(preds)\n", "    prec = precision_score(y_test, preds, zero_division=0)\n", "    rec = recall_score(y_test, preds, zero_division=0)\n", "    f1 = f1_score(y_test, preds, zero_division=0)\n", "    results.append({'threshold': round(t, 2), 'precision': prec, 'recall': rec,\n", "                    'f1': f1, 'signals': n_signals, 'coverage': round(coverage, 3)})\n", "\n", "threshold_df = pd.DataFrame(results)\n", "threshold_df"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, ax = plt.subplots(figsize=(10, 5))\n", "ax.plot(threshold_df['threshold'], threshold_df['precision'], 'o-', label='Precision', color='green')\n", "ax.plot(threshold_df['threshold'], threshold_df['recall'], 's-', label='Recall', color='orange')\n", "ax.plot(threshold_df['threshold'], threshold_df['coverage'], '^-', label='Coverage', color='blue')\n", "ax.set_xlabel('Decision Threshold')\n", "ax.set_ylabel('Score')\n", "ax.set_title('Precision / Recall / Coverage vs Threshold')\n", "ax.legend()\n", "ax.grid(True, alpha=0.3)\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- Precision generally improves as we raise the threshold (fewer but more confident signals)\n", "- Recall drops because we're filtering out more predictions\n", "- We need to find a balance $\\rightarrow$ let's also look at this from a strategy perspective"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Comparing the Model's Performance to Other Models\n", "\n", "Let's train a Logistic Regression and a Random Forest with the same data and see how they compare."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Logistic Regression\n", "lr_model = LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=4000, random_state=SEED)\n", "lr_model.fit(X_train, y_train)\n", "lr_pred = lr_model.predict(X_test)\n", "lr_proba = lr_model.predict_proba(X_test)[:, 1]\n", "\n", "print('=== Logistic Regression ===')\n", "print(classification_report(y_test, lr_pred, zero_division=0))"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Random Forest\n", "rf_model = RandomForestClassifier(\n", "    n_estimators=400, max_depth=8, min_samples_leaf=8,\n", "    class_weight='balanced_subsample', random_state=SEED, n_jobs=-1\n", ")\n", "rf_model.fit(X_train, y_train)\n", "rf_pred = rf_model.predict(X_test)\n", "rf_proba = rf_model.predict_proba(X_test)[:, 1]\n", "\n", "print('=== Random Forest ===')\n", "print(classification_report(y_test, rf_pred, zero_division=0))"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Comparison table\n", "from sklearn.metrics import average_precision_score\n", "\n", "models = {\n", "    'Logistic Regression': (lr_pred, lr_proba),\n", "    'Random Forest': (rf_pred, rf_proba),\n", "    'XGBoost': (test_pred, test_proba)\n", "}\n", "\n", "comparison = []\n", "for name, (preds, proba) in models.items():\n", "    try:\n", "        auc = roc_auc_score(y_test, proba)\n", "    except:\n", "        auc = 0\n", "    try:\n", "        pr_auc = average_precision_score(y_test, proba)\n", "    except:\n", "        pr_auc = 0\n", "\n", "    comparison.append({\n", "        'Model': name,\n", "        'Precision': precision_score(y_test, preds, zero_division=0),\n", "        'Recall': recall_score(y_test, preds, zero_division=0),\n", "        'F1': f1_score(y_test, preds, zero_division=0),\n", "        'ROC-AUC': auc,\n", "        'PR-AUC': pr_auc\n", "    })\n", "\n", "comparison_df = pd.DataFrame(comparison).round(4)\n", "comparison_df"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, ax = plt.subplots(figsize=(10, 5))\n", "comparison_df.set_index('Model')[['Precision', 'Recall', 'F1']].plot(kind='bar', ax=ax)\n", "ax.set_title('Model Comparison on Test Set')\n", "ax.set_ylabel('Score')\n", "ax.legend(loc='upper right')\n", "ax.set_xticklabels(comparison_df['Model'], rotation=0)\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- We can compare precision, recall, and F1 across the three models\n", "- For a trading strategy, precision is the most important metric because false positives cost money\n", "- The best model depends on the trade-off we want between precision and coverage"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Backtesting the Strategy\n", "\n", "Beyond ML metrics, we need to check whether the model actually makes money. We'll simulate a simple strategy: when the model says BUY, we go long; otherwise we stay in cash. We evaluate on non-overlapping 5-day windows to avoid inflated results."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["def backtest_strategy(df, proba, threshold=0.5, horizon=5):\n", "    \"\"\"Run a simple long/cash backtest on non-overlapping windows.\"\"\"\n", "    df = df.copy()\n", "    df['proba'] = proba\n", "    df['signal'] = (df['proba'] >= threshold).astype(int)\n", "\n", "    # Non-overlapping windows\n", "    df = df.iloc[::horizon].copy()\n", "    df['strategy_return'] = df['signal'] * df['future_return']\n", "\n", "    equity = (1 + df['strategy_return']).cumprod()\n", "\n", "    # Annualized return\n", "    total_ret = equity.iloc[-1] / equity.iloc[0] - 1\n", "    n_periods = len(equity)\n", "    periods_per_year = 252 / horizon\n", "    years = n_periods / periods_per_year\n", "    ann_ret = (1 + total_ret) ** (1 / max(years, 0.01)) - 1\n", "\n", "    # Sharpe ratio\n", "    strat_returns = df['strategy_return']\n", "    if strat_returns.std() > 0:\n", "        sharpe = (strat_returns.mean() / strat_returns.std()) * np.sqrt(periods_per_year)\n", "    else:\n", "        sharpe = 0\n", "\n", "    # Max drawdown\n", "    cum_max = equity.cummax()\n", "    mdd = (equity / cum_max - 1).min()\n", "\n", "    return {'ann_return': ann_ret, 'sharpe': sharpe, 'max_drawdown': mdd, 'equity': equity}"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Backtest at different thresholds\n", "bt_results = []\n", "for t in [0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70]:\n", "    res = backtest_strategy(test_df, test_proba, threshold=t)\n", "    bt_results.append({\n", "        'threshold': t,\n", "        'ann_return': round(res['ann_return'], 4),\n", "        'sharpe': round(res['sharpe'], 3),\n", "        'max_drawdown': round(res['max_drawdown'], 4)\n", "    })\n", "\n", "bt_df = pd.DataFrame(bt_results)\n", "bt_df"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n", "\n", "ax1.plot(bt_df['threshold'], bt_df['ann_return'], 'o-', color='green')\n", "ax1.set_xlabel('Threshold')\n", "ax1.set_ylabel('Annualized Return')\n", "ax1.set_title('Annualized Return vs Threshold')\n", "ax1.grid(True, alpha=0.3)\n", "\n", "ax2.plot(bt_df['threshold'], bt_df['sharpe'], 's-', color='steelblue')\n", "ax2.set_xlabel('Threshold')\n", "ax2.set_ylabel('Sharpe Ratio')\n", "ax2.set_title('Sharpe Ratio vs Threshold')\n", "ax2.grid(True, alpha=0.3)\n", "\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- The best threshold depends on whether we prioritize returns or risk-adjusted performance (Sharpe)\n", "- Lower thresholds generate more trades and potentially higher raw returns, but may also increase drawdown\n", "- Higher thresholds are more selective $\\rightarrow$ fewer trades but potentially better precision"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Equity Curve\n", "\n", "Let's visualize the equity curve at the best threshold by Sharpe ratio."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["best_bt_row = bt_df.loc[bt_df['sharpe'].idxmax()]\n", "best_threshold = best_bt_row['threshold']\n", "print(f'Best threshold by Sharpe: {best_threshold}')\n", "print(f'Sharpe: {best_bt_row[\"sharpe\"]}, Ann. Return: {best_bt_row[\"ann_return\"]:.2%}, Max DD: {best_bt_row[\"max_drawdown\"]:.2%}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["res = backtest_strategy(test_df, test_proba, threshold=best_threshold)\n", "equity = res['equity'].reset_index(drop=True)\n", "\n", "fig, ax = plt.subplots(figsize=(12, 5))\n", "ax.plot(equity.values, color='steelblue')\n", "ax.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5)\n", "ax.set_title(f'Equity Curve (threshold = {best_threshold})')\n", "ax.set_xlabel('Trading Period (5-day windows)')\n", "ax.set_ylabel('Portfolio Value (starting at 1.0)')\n", "ax.grid(True, alpha=0.3)\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Comparing to a Dummy Strategy\n", "\n", "Let's compare our model to two simple baselines:\n", "- **Random guess**: randomly predict BUY or CASH with equal probability\n", "- **Always cash**: never trade (return = 0)"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from sklearn.metrics import accuracy_score\n", "\n", "def random_guess(inputs):\n", "    return np.random.choice([0, 1], size=len(inputs))\n", "\n", "def always_cash(inputs):\n", "    return np.zeros(len(inputs))\n", "\n", "np.random.seed(SEED)\n", "rg_pred = random_guess(X_test)\n", "ac_pred = always_cash(X_test)\n", "\n", "best_preds = (test_proba >= best_threshold).astype(int)\n", "\n", "print(f'Model accuracy:        {accuracy_score(y_test, best_preds):.4f}')\n", "print(f'Random guess accuracy:  {accuracy_score(y_test, rg_pred):.4f}')\n", "print(f'Always-cash accuracy:   {accuracy_score(y_test, ac_pred):.4f}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["The model outperforms both dummy strategies. Even the always-cash strategy can have decent accuracy when the positive class is rare, but it generates zero return."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Feature Ablation\n", "\n", "Let's verify whether each group of features actually contributes. We'll drop one group at a time and check how precision changes."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Define feature groups by pattern matching on column names\n", "feature_groups = {\n", "    'volatility_atr': [c for c in input_cols if 'atr_' in c],\n", "    'macro_rates': [c for c in input_cols if 'ten_year_yield' in c],\n", "    'trend_momentum': [c for c in input_cols if any(k in c for k in ['rsi_', 'macd', 'bb_', 'ma_', 'volume_z'])]\n", "}\n", "\n", "for group, cols in feature_groups.items():\n", "    print(f'{group}: {len(cols)} features')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["ablation_results = [{'experiment': 'full_model',\n", "                     'precision': precision_score(y_test, test_pred, zero_division=0)}]\n", "\n", "for group, cols_to_drop in feature_groups.items():\n", "    remaining = [c for c in input_cols if c not in cols_to_drop]\n", "    if len(remaining) == 0:\n", "        continue\n", "\n", "    X_tr_abl = train_inputs_scaled[remaining].values\n", "    X_te_abl = test_inputs_scaled[remaining].values\n", "\n", "    abl_model = XGBClassifier(\n", "        n_estimators=300, max_depth=4, learning_rate=0.05,\n", "        subsample=0.9, colsample_bytree=0.9,\n", "        scale_pos_weight=spw, objective='binary:logistic',\n", "        eval_metric='logloss', random_state=SEED, n_jobs=-1\n", "    )\n", "    abl_model.fit(X_tr_abl, y_train)\n", "    abl_pred = abl_model.predict(X_te_abl)\n", "    prec = precision_score(y_test, abl_pred, zero_division=0)\n", "\n", "    ablation_results.append({'experiment': f'drop_{group}', 'precision': prec})\n", "    print(f'drop_{group}: precision = {prec:.4f}')\n", "\n", "ablation_df = pd.DataFrame(ablation_results)\n", "ablation_df"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["fig, ax = plt.subplots(figsize=(10, 5))\n", "colors = ['steelblue' if x == 'full_model' else 'coral' for x in ablation_df['experiment']]\n", "ax.barh(ablation_df['experiment'], ablation_df['precision'], color=colors)\n", "ax.set_xlabel('Precision')\n", "ax.set_title('Feature Ablation: Precision by Experiment')\n", "plt.tight_layout()\n", "plt.show()"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["- If dropping a feature group hurts precision, that group is valuable\n", "- If dropping a group doesn't change (or improves) precision, it may be adding noise\n", "- This helps us understand which features the model truly needs"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Results Summary"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Final decision table\n", "best_model_name = comparison_df.loc[comparison_df['Precision'].idxmax(), 'Model']\n", "best_ablation = ablation_df.loc[ablation_df['precision'].idxmax(), 'experiment']\n", "\n", "summary_table = pd.DataFrame([\n", "    {'Decision': 'Best model (by precision)', 'Choice': best_model_name},\n", "    {'Decision': 'Best threshold (by Sharpe)', 'Choice': str(best_threshold)},\n", "    {'Decision': 'Best ablation experiment', 'Choice': best_ablation},\n", "    {'Decision': 'Test Sharpe ratio', 'Choice': str(best_bt_row['sharpe'])},\n", "    {'Decision': 'Test annualized return', 'Choice': f'{best_bt_row[\"ann_return\"]:.2%}'},\n", "])\n", "summary_table"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Discussion\n", "\n", "**Strengths:**\n", "- Strict chronological validation prevents data leakage\n", "- Multiple model families compared under the same conditions\n", "- Threshold tuning with both ML metrics and strategy-level metrics (Sharpe, drawdown)\n", "- Feature ablation verifies which feature groups genuinely help\n", "\n", "**Weaknesses:**\n", "- The backtest does not account for transaction costs or slippage\n", "- Performance depends heavily on the market regime during the test period\n", "- Probability calibration is not applied (the raw probabilities may not be well-calibrated)\n", "\n", "**Practical takeaway:** The model works best as a decision support tool. The threshold should be chosen based on risk appetite: a lower threshold captures more opportunities but with less precision, while a higher threshold is more selective."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Saving the Model"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import joblib"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["model_artifacts = {\n", "    'model': final_model,\n", "    'scaler': scaler,\n", "    'input_cols': input_cols,\n", "    'threshold': best_threshold,\n", "    'config': {\n", "        'horizon_days': HORIZON,\n", "        'success_threshold': THRESHOLD,\n", "        'window_days': WINDOW,\n", "        'seed': SEED\n", "    }\n", "}\n", "\n", "save_path = os.path.join(data_dir, 'model_artifacts.joblib')\n", "joblib.dump(model_artifacts, save_path)\n", "print(f'Saved to {save_path}')"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Verify we can load it back\n", "loaded = joblib.load(save_path)\n", "print('Loaded model type:', type(loaded['model']))\n", "print('Number of features:', len(loaded['input_cols']))\n", "print('Config:', loaded['config'])"],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Conclusion\n", "\n", "We built a pipeline that predicts 5-day upside moves for high-volatility stocks. The key takeaways:\n", "\n", "- ATR-based volatility features are among the most important predictors for this regime\n", "- Threshold tuning has a big impact on practical performance $\\rightarrow$ model quality alone doesn't define trading quality\n", "- Feature ablation showed which feature groups actually contribute vs. which ones add noise\n", "- The strategy generates positive risk-adjusted returns on the 2023+ test period, but real-world deployment would need transaction cost modeling and continuous retraining"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Future Work\n", "\n", "- Add transaction costs and slippage to the backtest\n", "- Apply probability calibration (Platt scaling or isotonic regression)\n", "- Implement walk-forward retraining to adapt to changing market conditions\n", "- Explore alternative data sources: options flow, earnings events, intraday volatility\n", "- Test regime-switching between high-volatility and stable-stock configurations"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
