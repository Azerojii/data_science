{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860fe17c",
   "metadata": {},
   "source": [
    "# ü§ñ AI Stock Prediction: A Beginner's Walkthrough\n",
    "\n",
    "Welcome! This notebook will guide you through the **entire AI process** used in your project. We will take raw stock prices and turn them into a machine learning model that can predict future price movements (specifically for high-volatility stocks like SMCI, CRSP, PLTR).\n",
    "\n",
    "We will verify every step to ensure **no future data leakage** (cheating) occurs.\n",
    "\n",
    "### üìö What we will cover:\n",
    "1. **Setup**: Loading your project code.\n",
    "2. **Data Ingestion**: Getting the raw stock prices.\n",
    "3. **Feature Engineering**: Creating \"Features\" (Technical Indicators) that the AI learns from.\n",
    "4. **Data Preparation**: Creating \"Rolling Windows\" to organize data for the AI.\n",
    "5. **Model Training**: Training an **XGBoost** model (a very powerful AI algorithm).\n",
    "6. **Evaluation**: Checking if the model actually works (Precision, Backtesting).\n",
    "\n",
    "---\n",
    "## 1. Setup & Imports\n",
    "\n",
    "First, we need to import standard Python libraries (like pandas for data tables) and link this notebook to your existing code in the `src/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load env vars\n",
    "load_dotenv()\n",
    "\n",
    "# Add the 'src' directory to the system path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "print(f\"‚úÖ Setup complete. Linked to code in: {src_path}\")\n",
    "\n",
    "# Import your specific project modules\n",
    "from data_ingestion import download_price_data\n",
    "from features import add_technical_indicators, build_rolling_window_dataset\n",
    "from model import ModelConfig, train_xgboost_time_series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1ba93",
   "metadata": {},
   "source": [
    "## 2. Ingesting Data\n",
    "\n",
    "AI needs data to learn. We will download the stock history for our **High-Volatility Regime** tickers:\n",
    "- **SMCI** (Super Micro Computer)\n",
    "- **CRSP** (CRISPR Therapeutics)\n",
    "- **PLTR** (Palantir)\n",
    "- We also include stable stocks (AAPL etc.) if configured, but we focus on High Volatility now.\n",
    "\n",
    "This function `download_price_data()` automatically fetches the data from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b05f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Downloading (or loading) price data...\")\n",
    "df_prices = download_price_data()\n",
    "\n",
    "# Display the first few rows to see what raw data looks like\n",
    "print(f\"Loaded {len(df_prices)} rows of data.\")\n",
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcff5ff",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering (The \"Ingredients\")\n",
    "\n",
    "Raw prices (Open, High, Low, Close) are not enough for an AI. It needs **context**.\n",
    "We calculate **Technical Indicators** which act as features (variables the AI looks at).\n",
    "\n",
    "### What we calculate:\n",
    "*   **RSI (Relative Strength Index):** Is the stock overbought (expensive) or oversold (cheap)?\n",
    "*   **MACD:** Is the trend going up or down?\n",
    "*   **Bollinger Bands:** Is the volatility high or low?\n",
    "*   **ATR (Average True Range):** How much does the price move on average? (Crucial for our regime!)\n",
    "\n",
    "We use the function `add_technical_indicators(df)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86468415",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üõ†Ô∏è Calculating technical indicators...\")\n",
    "df_features = add_technical_indicators(df_prices)\n",
    "\n",
    "# Let's inspect the new columns we created\n",
    "new_columns = [c for c in df_features.columns if c not in df_prices.columns]\n",
    "print(f\"Created {len(new_columns)} new features: {new_columns}\")\n",
    "\n",
    "# Show SMCI's RSI and ATR\n",
    "df_features[df_features['ticker'] == 'SMCI'][['date', 'adj_close', 'rsi_14', 'atr_14']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e6c15",
   "metadata": {},
   "source": [
    "## 4. Preparing Data for the AI (Feature Windows)\n",
    "\n",
    "### üß† Concept: The \"Rolling Window\"\n",
    "This is the most critical part to understand for accurate prediction.\n",
    "\n",
    "Stock data is a time series. To predict what happens **next week** (Day T+5), the AI needs to know what happened in the **past 2 weeks** (Day T-14 to Day T).\n",
    "\n",
    "We structure the data into **Windows**:\n",
    "*   **Input (X):** Statistics (Mean, Std Dev, Last Value) of the past 14 days.\n",
    "    *   *Example:* \"What was the average RSI over the last 14 days?\"\n",
    "*   **Target (y):** Did the price go up > 3.5% in the **next** 5 days?\n",
    "    *   *Value:* 1 (Yes, Buy) or 0 (No, Cash).\n",
    "\n",
    "### üõ°Ô∏è Safety Check: Future Leakage\n",
    "We must ensure that the Input (X) **ONLY** contains data from the past, and the Target (y) is the **ONLY** thing looking at the future.\n",
    "\n",
    "We use `build_rolling_window_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our AI configuration\n",
    "config = ModelConfig()\n",
    "print(f\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"  - Lookback Window: {config.window_days} days (Feature extraction)\")\n",
    "print(f\"  - Prediction Horizon: {config.horizon_days} days (Forecasting)\")\n",
    "print(f\"  - Success Threshold: {config.threshold * 100}% gain needed to call it a 'BUY'\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Building the rolling window dataset (this aligns Past features with Future targets)...\")\n",
    "dataset = build_rolling_window_dataset(\n",
    "    df_features,\n",
    "    window_days=config.window_days,\n",
    "    horizon_days=config.horizon_days,\n",
    "    threshold=config.threshold\n",
    ")\n",
    "\n",
    "print(f\"Dataset Shape: {dataset.shape}\")\n",
    "dataset[['date', 'ticker', 'target', 'future_return', 'rsi_14_mean', 'atr_14_last']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d79260",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split\n",
    "\n",
    "We mimic real life. We train the AI on \"History\" (2020-2022) and test it on \"The Future\" (2023-Present).\n",
    "If we trained on 2024 data and tested on 2023, that would be cheating!\n",
    "\n",
    "*   **Training Set:** Data before Jan 1, 2023.\n",
    "*   **Test Set:** Data from Jan 1, 2023 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date to be safe\n",
    "dataset = dataset.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "cutoff_date = pd.Timestamp(\"2023-01-01\")\n",
    "\n",
    "# Create the split\n",
    "train_df = dataset[dataset[\"date\"] < cutoff_date].reset_index(drop=True)\n",
    "test_df = dataset[dataset[\"date\"] >= cutoff_date].reset_index(drop=True)\n",
    "\n",
    "print(f\"üìö Training Samples (History): {len(train_df)}\")\n",
    "print(f\"üìù Testing Samples (Future): {len(test_df)}\")\n",
    "\n",
    "# Prepare X (Features) and y (Target)\n",
    "# We DROP 'future_return' from X because that is the answer key!\n",
    "feature_cols = [c for c in dataset.columns if c not in ['ticker', 'date', 'target', 'future_return']]\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['target']\n",
    "\n",
    "print(f\"Number of input features used by AI: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c282dc",
   "metadata": {},
   "source": [
    "## 6. Training the Model (XGBoost)\n",
    "\n",
    "Variable `model` will be our AI brain. We use **XGBoost Classifier**.\n",
    "*   **Why XGBoost?** It is excellent for tabular data and time-series because it handles non-linear relationships and interactions between features better than simpler models.\n",
    "*   **CV (Cross-Validation):** We don't just train once. We train on chunks of time to ensure stability.\n",
    "\n",
    "We use the function `train_xgboost_time_series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß† Training AI Model...\")\n",
    "model, metrics = train_xgboost_time_series(X_train, y_train, config)\n",
    "\n",
    "print(f\"\\nüèÜ Best Training Precision: {metrics['cv_best_precision']:.2f}\")\n",
    "print(\"This means: When the model predicted a BUY during training, it was correct X% of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4141f",
   "metadata": {},
   "source": [
    "### üîç Feature Importance: What is the AI looking at?\n",
    "It's important to know *why* the AI makes a decision. We can plot which technical indicators were most important for the prediction.\n",
    "Often **ATR** (Volatility) and **RSI** (Momentum) are top predictors in high-volatility regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06441725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance\n",
    "importance = model.feature_importances_\n",
    "feat_imp = pd.DataFrame({'feature': feature_cols, 'importance': importance})\n",
    "feat_imp = feat_imp.sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feat_imp['feature'], feat_imp['importance'], color='skyblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Top 10 Features Used by AI')\n",
    "plt.gca().invert_yaxis() # Highest importance at top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6641e5",
   "metadata": {},
   "source": [
    "## 7. Evaluating on Test Data (The Moment of Truth)\n",
    "\n",
    "Now we give the AI the \"Test Exam\" (2023-2025 data).\n",
    "We convert its probability score (0 to 1) into a decision:\n",
    "*   **Probability >= 0.50:** BUY (Signal 1)\n",
    "*   **Probability < 0.50:** CASH (Signal 0)\n",
    "\n",
    "*Note: We use a Long-Only strategy. We do not short sell because it's too risky for these volatile stocks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4006ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "test_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert to signals (Long Only: Buy if prob >= 50%)\n",
    "test_signals = np.where(test_probs >= 0.50, 1, 0)\n",
    "\n",
    "# Add to dataframe for analysis\n",
    "results_df = test_df.copy()\n",
    "results_df['proba'] = test_probs\n",
    "results_df['signal'] = test_signals\n",
    "results_df['strategy_return'] = results_df['signal'] * results_df['future_return']\n",
    "\n",
    "print(\"Signal Distribution:\")\n",
    "print(results_df['signal'].value_counts())\n",
    "print(\"\\nSignal 0 = Cash, Signal 1 = Buy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5264acf",
   "metadata": {},
   "source": [
    "## 8. Backtest: Did we make money?\n",
    "\n",
    "We simulate what would have happened if we followed these signals.\n",
    "*We update our portfolio every 5 days (non-overlapping) to match our prediction horizon.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a100dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtest import max_drawdown\n",
    "\n",
    "# Filter for non-overlapping periods (every 5 days) to calculate realistic cumulative returns\n",
    "# This mimics trading: Buy Monday -> Hold 5 days -> Sell next Monday -> Re-evaluate\n",
    "trading_dates = sorted(results_df['date'].unique())[::config.horizon_days]\n",
    "backtest_df = results_df[results_df['date'].isin(trading_dates)].copy()\n",
    "\n",
    "# Calculate daily portfolio return (average of all active signals)\n",
    "portfolio_returns = backtest_df.groupby('date')['strategy_return'].mean()\n",
    "\n",
    "# Calculate Equity Curve (Starting at $1.00)\n",
    "equity_curve = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(equity_curve.index, equity_curve.values, label='AI Strategy (Long/Cash)', color='green', linewidth=2)\n",
    "plt.axhline(1.0, color='gray', linestyle='--')\n",
    "plt.title('Portfolio Performance (2023-Present)')\n",
    "plt.ylabel('Equity Multiplier (Start = 1.0)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Final Stats\n",
    "total_return = (equity_curve.iloc[-1] - 1) * 100\n",
    "print(f\"üí∞ Final Total Return: {total_return:.2f}%\")\n",
    "print(f\"üìâ Max Drawdown: {max_drawdown(equity_curve)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
